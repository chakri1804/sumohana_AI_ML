{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X_train = np.load(\"reshaped_14.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 2\n",
    "cov  = 2\n",
    "samples = 60000\n",
    "# input_size = 784\n",
    "input_size = 196\n",
    "# input_size = 100\n",
    "Xf = X_train.reshape(samples,input_size)\n",
    "Xf = Xf/255.0\n",
    "# defining functions\n",
    "\n",
    "np.random.seed(420)\n",
    "\n",
    "def sigm(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def diff_sigm(x):\n",
    "    return (sigm(x)-(sigm(x)**2))\n",
    "\n",
    "def relu(x):\n",
    "    x[x<0]=0\n",
    "    return x\n",
    "\n",
    "def relu(x, derivative=False):\n",
    "    res = x\n",
    "    return res * (res > 0)\n",
    "\n",
    "def diff_relu(x):\n",
    "    res = x\n",
    "    return res * (res > 1)\n",
    "\n",
    "def diff_SSE(y,x,batch_size):\n",
    "    return (2*(y-x))/batch_size\n",
    "\n",
    "def diff_CCE(y,x):\n",
    "    epsilon = 10e-8\n",
    "    loss = -y * np.log(x + epsilon) - (1 - y) * np.log(1 - x + epsilon)\n",
    "    return loss\n",
    "\n",
    "def layer(x,W,b):\n",
    "    return np.matmul(x,W)+b\n",
    "\n",
    "def backprop_layer_relu(prev_delta,out_prev,weights_prev):\n",
    "    sn = -(diff_relu(out_prev)*np.matmul(prev_delta,weights_prev.T))\n",
    "    return sn\n",
    "\n",
    "def backprop_layer_sigm(prev_delta,out_prev,weights_prev):\n",
    "    sn = -(diff_sigm(out_prev)*np.matmul(prev_delta,weights_prev.T))\n",
    "    return sn\n",
    "\n",
    "Wc = np.random.normal(0,1e-3,(input_size,mean))\n",
    "Bc = np.random.normal(0,1e-3,(1,mean))\n",
    "\n",
    "Wm = np.random.normal(0,1e-3,(input_size,mean))\n",
    "Bm = np.random.normal(0,1e-3,(1,mean))\n",
    "\n",
    "Wd = np.random.normal(0,1e-3,(mean,input_size))\n",
    "Bd = np.random.normal(0,1e-3,(1,input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899.8496186693774, 'epoch = ', 0, 'batch =', 599)\n",
      "(850.4838997129596, 'epoch = ', 1, 'batch =', 599)\n",
      "(805.7807807381796, 'epoch = ', 2, 'batch =', 599)\n",
      "(765.9449457314721, 'epoch = ', 3, 'batch =', 599)\n",
      "(730.590339970294, 'epoch = ', 4, 'batch =', 599)\n",
      "(699.5653430784918, 'epoch = ', 5, 'batch =', 599)\n",
      "(672.1898831655749, 'epoch = ', 6, 'batch =', 599)\n",
      "(648.1679684924679, 'epoch = ', 7, 'batch =', 599)\n",
      "(626.9140563407058, 'epoch = ', 8, 'batch =', 599)\n",
      "(608.0809000729639, 'epoch = ', 9, 'batch =', 599)\n",
      "(591.3606625193395, 'epoch = ', 10, 'batch =', 599)\n",
      "(576.4111196847148, 'epoch = ', 11, 'batch =', 599)\n",
      "(562.9746597974278, 'epoch = ', 12, 'batch =', 599)\n",
      "(550.8906872898183, 'epoch = ', 13, 'batch =', 599)\n",
      "(539.9526289679427, 'epoch = ', 14, 'batch =', 599)\n",
      "(529.9980151263486, 'epoch = ', 15, 'batch =', 599)\n",
      "(520.9424525105427, 'epoch = ', 16, 'batch =', 599)\n",
      "(512.6399258126312, 'epoch = ', 17, 'batch =', 599)\n",
      "(505.02545166973937, 'epoch = ', 18, 'batch =', 599)\n",
      "(498.01664735013856, 'epoch = ', 19, 'batch =', 599)\n",
      "(491.512030404899, 'epoch = ', 20, 'batch =', 599)\n",
      "(485.4989544998231, 'epoch = ', 21, 'batch =', 599)\n",
      "(479.9168005433288, 'epoch = ', 22, 'batch =', 599)\n",
      "(474.7311203013527, 'epoch = ', 23, 'batch =', 599)\n",
      "(469.8516406240792, 'epoch = ', 24, 'batch =', 599)\n",
      "(465.3144777019837, 'epoch = ', 25, 'batch =', 599)\n",
      "(461.0279782674677, 'epoch = ', 26, 'batch =', 599)\n",
      "(456.99728809403484, 'epoch = ', 27, 'batch =', 599)\n",
      "(453.2208439853886, 'epoch = ', 28, 'batch =', 599)\n",
      "(449.68115442612714, 'epoch = ', 29, 'batch =', 599)\n",
      "(446.3130776375399, 'epoch = ', 30, 'batch =', 599)\n",
      "(443.14324852509037, 'epoch = ', 31, 'batch =', 599)\n",
      "(440.1079866576409, 'epoch = ', 32, 'batch =', 599)\n",
      "(437.2468656003949, 'epoch = ', 33, 'batch =', 599)\n",
      "(434.5077653922357, 'epoch = ', 34, 'batch =', 599)\n",
      "(431.9084825603984, 'epoch = ', 35, 'batch =', 599)\n",
      "(429.4433219684845, 'epoch = ', 36, 'batch =', 599)\n",
      "(427.0806893635163, 'epoch = ', 37, 'batch =', 599)\n",
      "(424.8281360145694, 'epoch = ', 38, 'batch =', 599)\n",
      "(422.6759751844718, 'epoch = ', 39, 'batch =', 599)\n",
      "(420.61200009869356, 'epoch = ', 40, 'batch =', 599)\n",
      "(418.62846373898753, 'epoch = ', 41, 'batch =', 599)\n",
      "(416.7266004470901, 'epoch = ', 42, 'batch =', 599)\n",
      "(414.9080822642248, 'epoch = ', 43, 'batch =', 599)\n",
      "(413.152107403949, 'epoch = ', 44, 'batch =', 599)\n",
      "(411.48595832022, 'epoch = ', 45, 'batch =', 599)\n",
      "(409.8566368190639, 'epoch = ', 46, 'batch =', 599)\n",
      "(408.28814654915453, 'epoch = ', 47, 'batch =', 599)\n",
      "(406.7846486125849, 'epoch = ', 48, 'batch =', 599)\n",
      "(405.3432052924852, 'epoch = ', 49, 'batch =', 599)\n",
      "(403.9391869470136, 'epoch = ', 50, 'batch =', 599)\n",
      "(402.57380746380295, 'epoch = ', 51, 'batch =', 599)\n",
      "(401.2794658564392, 'epoch = ', 52, 'batch =', 599)\n",
      "(400.00438982297464, 'epoch = ', 53, 'batch =', 599)\n",
      "(398.7696759057424, 'epoch = ', 54, 'batch =', 599)\n",
      "(397.5844905978598, 'epoch = ', 55, 'batch =', 599)\n",
      "(396.43693532668146, 'epoch = ', 56, 'batch =', 599)\n",
      "(395.3165519217083, 'epoch = ', 57, 'batch =', 599)\n",
      "(394.2286608926531, 'epoch = ', 58, 'batch =', 599)\n",
      "(393.1855600977553, 'epoch = ', 59, 'batch =', 599)\n",
      "(392.1622023859751, 'epoch = ', 60, 'batch =', 599)\n",
      "(391.18053706397177, 'epoch = ', 61, 'batch =', 599)\n",
      "(390.2130155068362, 'epoch = ', 62, 'batch =', 599)\n",
      "(389.26180265415184, 'epoch = ', 63, 'batch =', 599)\n",
      "(388.3511833715128, 'epoch = ', 64, 'batch =', 599)\n",
      "(387.46772955521317, 'epoch = ', 65, 'batch =', 599)\n",
      "(386.60573070937255, 'epoch = ', 66, 'batch =', 599)\n",
      "(385.76774506382105, 'epoch = ', 67, 'batch =', 599)\n",
      "(384.9319746582647, 'epoch = ', 68, 'batch =', 599)\n",
      "(384.12942777558044, 'epoch = ', 69, 'batch =', 599)\n",
      "(383.35446784785995, 'epoch = ', 70, 'batch =', 599)\n",
      "(382.59808276531703, 'epoch = ', 71, 'batch =', 599)\n",
      "(381.8597877358531, 'epoch = ', 72, 'batch =', 599)\n",
      "(381.1272455460018, 'epoch = ', 73, 'batch =', 599)\n",
      "(380.42162591196063, 'epoch = ', 74, 'batch =', 599)\n",
      "(379.72958612431364, 'epoch = ', 75, 'batch =', 599)\n",
      "(379.0491781277078, 'epoch = ', 76, 'batch =', 599)\n",
      "(378.394863359838, 'epoch = ', 77, 'batch =', 599)\n",
      "(377.74701573421737, 'epoch = ', 78, 'batch =', 599)\n",
      "(377.1093193171124, 'epoch = ', 79, 'batch =', 599)\n",
      "(376.50633146005146, 'epoch = ', 80, 'batch =', 599)\n",
      "(375.88342791758055, 'epoch = ', 81, 'batch =', 599)\n",
      "(375.2955914098347, 'epoch = ', 82, 'batch =', 599)\n",
      "(374.7184455786181, 'epoch = ', 83, 'batch =', 599)\n",
      "(374.13105621197474, 'epoch = ', 84, 'batch =', 599)\n",
      "(373.5988694011453, 'epoch = ', 85, 'batch =', 599)\n",
      "(373.0613539932491, 'epoch = ', 86, 'batch =', 599)\n",
      "(372.5140914849952, 'epoch = ', 87, 'batch =', 599)\n",
      "(371.9891011075956, 'epoch = ', 88, 'batch =', 599)\n",
      "(371.47788457362304, 'epoch = ', 89, 'batch =', 599)\n",
      "(370.96943189063586, 'epoch = ', 90, 'batch =', 599)\n",
      "(370.49003512448553, 'epoch = ', 91, 'batch =', 599)\n",
      "(369.9874131984352, 'epoch = ', 92, 'batch =', 599)\n",
      "(369.5151663343829, 'epoch = ', 93, 'batch =', 599)\n",
      "(369.0408822391796, 'epoch = ', 94, 'batch =', 599)\n",
      "(368.59758098257794, 'epoch = ', 95, 'batch =', 599)\n",
      "(368.1351653686884, 'epoch = ', 96, 'batch =', 599)\n",
      "(367.69147721183447, 'epoch = ', 97, 'batch =', 599)\n",
      "(367.28206949629043, 'epoch = ', 98, 'batch =', 599)\n",
      "(366.83017620617, 'epoch = ', 99, 'batch =', 599)\n",
      "(366.4121203676201, 'epoch = ', 100, 'batch =', 599)\n",
      "(365.99658906989043, 'epoch = ', 101, 'batch =', 599)\n",
      "(365.60330977597766, 'epoch = ', 102, 'batch =', 599)\n",
      "(365.18816220769025, 'epoch = ', 103, 'batch =', 599)\n",
      "(364.80827557527573, 'epoch = ', 104, 'batch =', 599)\n",
      "(364.43238779607674, 'epoch = ', 105, 'batch =', 599)\n",
      "(364.04462773465116, 'epoch = ', 106, 'batch =', 599)\n",
      "(363.6797020668563, 'epoch = ', 107, 'batch =', 599)\n",
      "(363.29700484011397, 'epoch = ', 108, 'batch =', 599)\n",
      "(362.9344243554918, 'epoch = ', 109, 'batch =', 599)\n",
      "(362.58206365826663, 'epoch = ', 110, 'batch =', 599)\n",
      "(362.2328622038767, 'epoch = ', 111, 'batch =', 599)\n",
      "(361.8861646089791, 'epoch = ', 112, 'batch =', 599)\n",
      "(361.5351969151681, 'epoch = ', 113, 'batch =', 599)\n",
      "(361.21091780609663, 'epoch = ', 114, 'batch =', 599)\n",
      "(360.87216314971863, 'epoch = ', 115, 'batch =', 599)\n",
      "(360.56068065319505, 'epoch = ', 116, 'batch =', 599)\n",
      "(360.2442416638159, 'epoch = ', 117, 'batch =', 599)\n",
      "(359.92604492028624, 'epoch = ', 118, 'batch =', 599)\n",
      "(359.6095395914382, 'epoch = ', 119, 'batch =', 599)\n",
      "(359.2986420158905, 'epoch = ', 120, 'batch =', 599)\n",
      "(358.9941045741275, 'epoch = ', 121, 'batch =', 599)\n",
      "(358.7083203532639, 'epoch = ', 122, 'batch =', 599)\n",
      "(358.4021997320048, 'epoch = ', 123, 'batch =', 599)\n",
      "(358.1206397289743, 'epoch = ', 124, 'batch =', 599)\n",
      "(357.8425484206284, 'epoch = ', 125, 'batch =', 599)\n",
      "(357.56550649675194, 'epoch = ', 126, 'batch =', 599)\n",
      "(357.2699168556545, 'epoch = ', 127, 'batch =', 599)\n",
      "(356.9976693995102, 'epoch = ', 128, 'batch =', 599)\n",
      "(356.7205298187182, 'epoch = ', 129, 'batch =', 599)\n",
      "(356.44845095416406, 'epoch = ', 130, 'batch =', 599)\n",
      "(356.1985274824958, 'epoch = ', 131, 'batch =', 599)\n",
      "(355.9366535686528, 'epoch = ', 132, 'batch =', 599)\n",
      "(355.6810690262299, 'epoch = ', 133, 'batch =', 599)\n",
      "(355.4195511933973, 'epoch = ', 134, 'batch =', 599)\n",
      "(355.1827027961326, 'epoch = ', 135, 'batch =', 599)\n",
      "(354.9108283328075, 'epoch = ', 136, 'batch =', 599)\n",
      "(354.68051180029886, 'epoch = ', 137, 'batch =', 599)\n",
      "(354.4399222080373, 'epoch = ', 138, 'batch =', 599)\n",
      "(354.2127021907339, 'epoch = ', 139, 'batch =', 599)\n",
      "(353.96710135984574, 'epoch = ', 140, 'batch =', 599)\n",
      "(353.74704993038847, 'epoch = ', 141, 'batch =', 599)\n",
      "(353.5193064438792, 'epoch = ', 142, 'batch =', 599)\n",
      "(353.2874416467047, 'epoch = ', 143, 'batch =', 599)\n",
      "(353.07001426173224, 'epoch = ', 144, 'batch =', 599)\n",
      "(352.83849345556644, 'epoch = ', 145, 'batch =', 599)\n",
      "(352.6129496308571, 'epoch = ', 146, 'batch =', 599)\n",
      "(352.3979325359105, 'epoch = ', 147, 'batch =', 599)\n",
      "(352.18869647877443, 'epoch = ', 148, 'batch =', 599)\n",
      "(351.9654547391276, 'epoch = ', 149, 'batch =', 599)\n",
      "(351.7570395946051, 'epoch = ', 150, 'batch =', 599)\n",
      "(351.55798240582124, 'epoch = ', 151, 'batch =', 599)\n",
      "(351.35081630907973, 'epoch = ', 152, 'batch =', 599)\n",
      "(351.15736737776064, 'epoch = ', 153, 'batch =', 599)\n",
      "(350.95155190646153, 'epoch = ', 154, 'batch =', 599)\n",
      "(350.7645140531715, 'epoch = ', 155, 'batch =', 599)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350.5412542108656, 'epoch = ', 156, 'batch =', 599)\n",
      "(350.35858612253924, 'epoch = ', 157, 'batch =', 599)\n",
      "(350.17885011435203, 'epoch = ', 158, 'batch =', 599)\n",
      "(349.97561837397524, 'epoch = ', 159, 'batch =', 599)\n",
      "(349.80891248274327, 'epoch = ', 160, 'batch =', 599)\n",
      "(349.614164280713, 'epoch = ', 161, 'batch =', 599)\n",
      "(349.4314404953425, 'epoch = ', 162, 'batch =', 599)\n",
      "(349.24164729339196, 'epoch = ', 163, 'batch =', 599)\n",
      "(349.068979454923, 'epoch = ', 164, 'batch =', 599)\n",
      "(348.9009429781352, 'epoch = ', 165, 'batch =', 599)\n",
      "(348.7073332894857, 'epoch = ', 166, 'batch =', 599)\n",
      "(348.52352117241276, 'epoch = ', 167, 'batch =', 599)\n",
      "(348.37611692842677, 'epoch = ', 168, 'batch =', 599)\n",
      "(348.18830238366985, 'epoch = ', 169, 'batch =', 599)\n",
      "(348.02005746099985, 'epoch = ', 170, 'batch =', 599)\n",
      "(347.8747887623789, 'epoch = ', 171, 'batch =', 599)\n",
      "(347.7096458472588, 'epoch = ', 172, 'batch =', 599)\n",
      "(347.5318330717822, 'epoch = ', 173, 'batch =', 599)\n",
      "(347.3685975755501, 'epoch = ', 174, 'batch =', 599)\n",
      "(347.19840657815007, 'epoch = ', 175, 'batch =', 599)\n",
      "(347.05117124279866, 'epoch = ', 176, 'batch =', 599)\n",
      "(346.8792780014054, 'epoch = ', 177, 'batch =', 599)\n",
      "(346.7414148880307, 'epoch = ', 178, 'batch =', 599)\n",
      "(346.5881930551122, 'epoch = ', 179, 'batch =', 599)\n",
      "(346.4215911061855, 'epoch = ', 180, 'batch =', 599)\n",
      "(346.27105355185836, 'epoch = ', 181, 'batch =', 599)\n",
      "(346.1365474756766, 'epoch = ', 182, 'batch =', 599)\n",
      "(345.9722476724909, 'epoch = ', 183, 'batch =', 599)\n",
      "(345.8300177131922, 'epoch = ', 184, 'batch =', 599)\n",
      "(345.6838139475052, 'epoch = ', 185, 'batch =', 599)\n",
      "(345.54327924932, 'epoch = ', 186, 'batch =', 599)\n",
      "(345.3962360476727, 'epoch = ', 187, 'batch =', 599)\n",
      "(345.2462817142631, 'epoch = ', 188, 'batch =', 599)\n",
      "(345.1057911943715, 'epoch = ', 189, 'batch =', 599)\n",
      "(344.97276914835203, 'epoch = ', 190, 'batch =', 599)\n",
      "(344.83106112518294, 'epoch = ', 191, 'batch =', 599)\n",
      "(344.6997554175439, 'epoch = ', 192, 'batch =', 599)\n",
      "(344.5509684107717, 'epoch = ', 193, 'batch =', 599)\n",
      "(344.4283565918203, 'epoch = ', 194, 'batch =', 599)\n",
      "(344.28209880354643, 'epoch = ', 195, 'batch =', 599)\n",
      "(344.1485270057092, 'epoch = ', 196, 'batch =', 599)\n",
      "(344.0267208132947, 'epoch = ', 197, 'batch =', 599)\n",
      "(343.8945464534017, 'epoch = ', 198, 'batch =', 599)\n",
      "(343.7613191411158, 'epoch = ', 199, 'batch =', 599)\n",
      "(343.63976288077424, 'epoch = ', 200, 'batch =', 599)\n",
      "(343.50742286626627, 'epoch = ', 201, 'batch =', 599)\n",
      "(343.38272423073545, 'epoch = ', 202, 'batch =', 599)\n",
      "(343.26113028255736, 'epoch = ', 203, 'batch =', 599)\n",
      "(343.1435740132107, 'epoch = ', 204, 'batch =', 599)\n",
      "(343.0143940895607, 'epoch = ', 205, 'batch =', 599)\n",
      "(342.89385693107755, 'epoch = ', 206, 'batch =', 599)\n",
      "(342.76731050397393, 'epoch = ', 207, 'batch =', 599)\n",
      "(342.64868109739666, 'epoch = ', 208, 'batch =', 599)\n",
      "(342.5333329378782, 'epoch = ', 209, 'batch =', 599)\n",
      "(342.4173932837382, 'epoch = ', 210, 'batch =', 599)\n",
      "(342.3073260329156, 'epoch = ', 211, 'batch =', 599)\n",
      "(342.17569423324994, 'epoch = ', 212, 'batch =', 599)\n",
      "(342.0714347508774, 'epoch = ', 213, 'batch =', 599)\n",
      "(341.962017913337, 'epoch = ', 214, 'batch =', 599)\n",
      "(341.8455586988561, 'epoch = ', 215, 'batch =', 599)\n",
      "(341.72373752971765, 'epoch = ', 216, 'batch =', 599)\n",
      "(341.6059842838367, 'epoch = ', 217, 'batch =', 599)\n",
      "(341.49738020806666, 'epoch = ', 218, 'batch =', 599)\n",
      "(341.3984627132059, 'epoch = ', 219, 'batch =', 599)\n",
      "(341.28994880305453, 'epoch = ', 220, 'batch =', 599)\n",
      "(341.1816148287679, 'epoch = ', 221, 'batch =', 599)\n",
      "(341.070883449647, 'epoch = ', 222, 'batch =', 599)\n",
      "(340.962883626711, 'epoch = ', 223, 'batch =', 599)\n",
      "(340.86011593494607, 'epoch = ', 224, 'batch =', 599)\n",
      "(340.7482902800688, 'epoch = ', 225, 'batch =', 599)\n",
      "(340.6432682912691, 'epoch = ', 226, 'batch =', 599)\n",
      "(340.54905769522327, 'epoch = ', 227, 'batch =', 599)\n",
      "(340.45136472358286, 'epoch = ', 228, 'batch =', 599)\n",
      "(340.34231346751363, 'epoch = ', 229, 'batch =', 599)\n",
      "(340.2347526999521, 'epoch = ', 230, 'batch =', 599)\n",
      "(340.1328762445291, 'epoch = ', 231, 'batch =', 599)\n",
      "(340.03526981182824, 'epoch = ', 232, 'batch =', 599)\n",
      "(339.9437137095087, 'epoch = ', 233, 'batch =', 599)\n",
      "(339.83746860020125, 'epoch = ', 234, 'batch =', 599)\n",
      "(339.74920052911506, 'epoch = ', 235, 'batch =', 599)\n",
      "(339.6501550627472, 'epoch = ', 236, 'batch =', 599)\n",
      "(339.55183823148263, 'epoch = ', 237, 'batch =', 599)\n",
      "(339.4563267182722, 'epoch = ', 238, 'batch =', 599)\n",
      "(339.3608445364314, 'epoch = ', 239, 'batch =', 599)\n",
      "(339.26491982752015, 'epoch = ', 240, 'batch =', 599)\n",
      "(339.1708331066027, 'epoch = ', 241, 'batch =', 599)\n",
      "(339.08811530233754, 'epoch = ', 242, 'batch =', 599)\n",
      "(338.9938704445066, 'epoch = ', 243, 'batch =', 599)\n"
     ]
    }
   ],
   "source": [
    "#Here the covariance is log coavriance but named as coavriance for peace of mind while coding\n",
    "lr = 1e-3\n",
    "epochs = 300\n",
    "batch_size = 100\n",
    "Lambda = 0.5\n",
    "number_of_batches = samples/batch_size\n",
    "X_t = Xf\n",
    "# plt.imshow(X[1][10].reshape(14,14), cmap='gray')\n",
    "for i in range(epochs):\n",
    "    wm = np.zeros(Wm.shape)\n",
    "    bm = np.zeros(Bm.shape)\n",
    "    wc = np.zeros(Wc.shape)\n",
    "    bc = np.zeros(Bc.shape)\n",
    "    wd = np.zeros(Wd.shape)\n",
    "    bd = np.zeros(Bd.shape)\n",
    "    for j in range(number_of_batches):\n",
    "        X = (X_t[j*batch_size:(j+1)*batch_size])\n",
    "#         print(X.shape)\n",
    "        loss = 0\n",
    "        #forward pass\n",
    "        outm = layer(X,Wm,Bm)\n",
    "        mean  = relu(outm)\n",
    "        outc = layer(X,Wc,Bc)\n",
    "        cova  = relu(outc)\n",
    "        gaus = np.random.normal(0,1,(cova.shape))\n",
    "        Z    = mean + np.multiply((np.exp(0.5*cova)),gaus)\n",
    "        outy = layer(Z,Wd,Bd)\n",
    "        y    = sigm(outy)\n",
    "        # Backprop decoder part \n",
    "        temp = diff_SSE(y,X,batch_size)*diff_sigm(outy)\n",
    "        bd   += np.sum(temp,axis=0)\n",
    "        wd   += np.matmul(Z.T,temp)\n",
    "    \n",
    "        ### Backprop Encoder part\n",
    "        sct = -0.5*gaus*np.exp(0.5*cova)*np.matmul(temp,Wd.T)*diff_relu(outc)\n",
    "        smt = -np.matmul(temp,Wd.T)*diff_relu(outm)\n",
    "        sm = smt + 2*(mean)*diff_relu(outm)*Lambda\n",
    "    #     print(smt.shape, outm.shape, cova.shape)\n",
    "        sc = sct + 0.5*(np.exp(cova)-1)*diff_relu(outc)*Lambda\n",
    "    #     print(smt)    \n",
    "        ### \n",
    "    \n",
    "        bm += np.sum(sm, axis=0).reshape(bm.shape)\n",
    "        wm += np.matmul(X.T,sm)\n",
    "    \n",
    "        bc += np.sum(sc, axis=0).reshape(bc.shape)\n",
    "        wc += np.matmul(X.T,sc)\n",
    "    \n",
    "        loss_1 = np.sum(np.linalg.norm(y-X, axis=0))\n",
    "        loss_2 = np.sum(np.exp(cova)-1-cova + mean*mean ,axis=1)/batch_size\n",
    "        loss   = loss_1 + np.sum(loss_2)\n",
    "    \n",
    "    Wm -= lr*wm\n",
    "    Bm -= lr*bm\n",
    "    Wc -= lr*wc\n",
    "    Bc -= lr*bc\n",
    "    Bd -= lr*bd\n",
    "    Wd -= lr*wd\n",
    "\n",
    "    print(loss, \"epoch = \", i, \"batch =\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=14\n",
    "h=14\n",
    "fig=plt.figure(figsize=(w/2,h/2))\n",
    "columns = 4\n",
    "rows = 4\n",
    "for i in range(1, columns*rows +1):\n",
    "    Z = np.random.normal(-10,10,(Bc.shape))\n",
    "#     Z    = mean + np.multiply((np.exp(0.5*cova)),gaus)\n",
    "    outy = layer(Z,Wd,Bd)\n",
    "    y    = sigm(outy)\n",
    "    img = y.reshape(w,h)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Wd = np.random.normal(0,1e-3,(100,input_size))\n",
    "Bd = np.random.normal(0,1e-3,(1,input_size))\n",
    "\n",
    "Wdi = np.random.normal(0,1,(mean,100))\n",
    "Bdi = np.random.normal(0,1,(1,100))\n",
    "\n",
    "#Here the covariance is log coavriance but named as coavriance for peace of mind while coding\n",
    "lr = 1e-4\n",
    "epochs = 300\n",
    "batch_size = 60\n",
    "number_of_batches = samples/batch_size\n",
    "X_t = Xf.reshape(number_of_batches,batch_size,input_size)\n",
    "# plt.imshow(X[1][10].reshape(14,14), cmap='gray')\n",
    "for i in range(epochs):\n",
    "    for j in range(number_of_batches):\n",
    "        X = (X_t[j])\n",
    "        # print(X.shape)\n",
    "        loss = 0\n",
    "        wm = np.zeros(Wm.shape)\n",
    "        bm = np.zeros(Bm.shape)\n",
    "        wc = np.zeros(Wc.shape)\n",
    "        bc = np.zeros(Bc.shape)\n",
    "        wd = np.zeros(Wd.shape)\n",
    "        bd = np.zeros(Bd.shape)\n",
    "        wdi = np.zeros(Wdi.shape)\n",
    "        bdi = np.zeros(Bdi.shape)\n",
    "        # forward pass\n",
    "#         outi = layer(X,Wi,Bi)\n",
    "#         aouti = sigm(outi)\n",
    "        outm = layer(X,Wm,Bm)\n",
    "        mean  = relu(outm)\n",
    "        outc = layer(X,Wc,Bc)\n",
    "        cova  = relu(outc)\n",
    "    \n",
    "    \n",
    "        gaus = np.random.normal(0,1,(cova.shape))\n",
    "        Z    = mean + np.multiply((np.exp(0.5*cova)),gaus)\n",
    "        outyi = layer(Z,Wdi,Bdi)\n",
    "        yi   = relu(outyi)\n",
    "        outy = layer(yi,Wd,Bd)\n",
    "        y = sigm(outy)\n",
    "        \n",
    "        # Backprop decoder part \n",
    "        temp = diff_SSE(y,X,batch_size)*diff_sigm(outy)\n",
    "        bd   = np.sum(temp,axis=0)\n",
    "        wd   = np.matmul(yi.T,temp)\n",
    "        \n",
    "        temp1 = backprop_layer_relu(temp,outyi,Wd)\n",
    "        bdi  = np.sum(temp1, axis=0)\n",
    "        wdi  = np.matmul(Z.T,temp1)\n",
    "    \n",
    "        ### Backprop Encoder part\n",
    "        sct = -0.5*gaus*np.exp(0.5*cova)*backprop_layer_relu(temp1,np.exp(0.5*cova),Wdi)\n",
    "        smt = -backprop_layer_relu(temp1,outm,Wdi)\n",
    "        sm = smt + 2*(mean)*diff_relu(outm)                                                                            \n",
    "    #     print(smt.shape, outm.shape, cova.shape)\n",
    "        sc = sct + 0.5*(np.exp(cova)-1)*diff_relu(outc)\n",
    "    #     print(smt)    \n",
    "        ### \n",
    "    \n",
    "        bm = np.sum(sm, axis=0).reshape(bm.shape)\n",
    "        wm = np.matmul(X.T,sm)\n",
    "    \n",
    "        bc = np.sum(sc, axis=0).reshape(bc.shape)\n",
    "        wc = np.matmul(X.T,sc)\n",
    "        \n",
    "        # we add up the sigmas coming from the previous layer to justify the divergence of \n",
    "        # one layer output to two others\n",
    "        \n",
    "        # Technically the functional output of the mean and variance layer to Z latent variable\n",
    "        # Can be modelled as the identity and exp() functions and backprop can be done but gets a bit tedious\n",
    "        # to define cases for all possible activations before that layer.\n",
    "        \n",
    "#         si = backprop_layer_sigm(sm,outi,Wm)+backprop_layer_sigm(sc,outi,Wc)\n",
    "#         bi = np.sum(si, axis=0).reshape(bi.shape)\n",
    "#         wi = np.matmul(X.T,si)\n",
    "    \n",
    "        loss_1 = np.sum(np.linalg.norm(y-X, axis=0))\n",
    "        loss_2 = np.sum(np.exp(cova)-1-cova + mean*mean ,axis=1)\n",
    "        loss   = loss_1 + np.sum(loss_2)\n",
    "        \n",
    "#         print(Wc.shape, wc.shape)\n",
    "        \n",
    "        Wm -= lr*wm\n",
    "        Bm -= lr*bm\n",
    "        Wc -= lr*wc\n",
    "        Bc -= lr*bc\n",
    "        Bd -= lr*bd\n",
    "        Wd -= lr*wd\n",
    "        Wdi -= lr*wdi\n",
    "        Bdi -= lr*bdi\n",
    "    print(loss)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

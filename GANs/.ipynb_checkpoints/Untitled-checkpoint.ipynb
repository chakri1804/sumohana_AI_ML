{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loss_function(input):\n",
    "    loss = log(discriminator(Generator(input)))\n",
    "    return loss\n",
    "\n",
    "def discriminator_loss_function(input):\n",
    "    loss = log(discriminator(input))\n",
    "    return loss\n",
    "\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build Discriminative model ...\n",
    "# d_input = Input(shape=shp)\n",
    "# H = Convolution2D(256, 5, 5, subsample=(2, 2), border_mode = 'same', activation='relu')(d_input)\n",
    "# H = LeakyReLU(0.2)(H)\n",
    "# H = Dropout(dropout_rate)(H)\n",
    "# H = Convolution2D(512, 5, 5, subsample=(2, 2), border_mode = 'same', activation='relu')(H)\n",
    "# H = LeakyReLU(0.2)(H)\n",
    "# H = Dropout(dropout_rate)(H)\n",
    "# H = Flatten()(H)\n",
    "# H = Dense(256)(H)\n",
    "# H = LeakyReLU(0.2)(H)\n",
    "# H = Dropout(dropout_rate)(H)\n",
    "# d_V = Dense(2,activation='softmax')(H)\n",
    "# discriminator = Model(d_input,d_V)\n",
    "# discriminator.compile(loss='categorical_crossentropy', optimizer=dopt)\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "g_input = Input(shape=(1,))\n",
    "H = UpSampling2D(size=(2,2))(g_input)\n",
    "H = Activation('LeakyReLU')(H)\n",
    "H = UpSampling2D(size=(4,4))(H)\n",
    "H = Activation('LeakyReLU')(H)\n",
    "H = UpSampling2D(size=(8,8))(H)\n",
    "H = Activation('LeakyReLU')(H)\n",
    "H = UpSampling2D(size=(16,16))(H)\n",
    "H = Activation('LeakyReLU')(H)\n",
    "H = UpSampling2D(size=(28,28))(H)\n",
    "H = Activation('LeakyReLU')(H)\n",
    "generator = Model(g_input,H)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n",
    "\n",
    "# Discriminator Model\n",
    "d_input = Input(shape=(28,28))\n",
    "H = Flatten()(d_input)\n",
    "H = Dense()(H)\n",
    "H = Activation('LeakyReLU')(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(shape):\n",
    "    X = np.random.normal(0,1,shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training for Discriminator\n",
    "ntrain = 10000\n",
    "trainidx = random.sample(range(0,X_train.shape[0]), ntrain)\n",
    "XT = X_train[trainidx,:,:,:]\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = discriminator()\n",
    "noise_gen = np.random.uniform(0,1,size=[XT.shape[0],100])\n",
    "generated_images = generator.predict(noise_gen)\n",
    "X = np.concatenate((XT, generated_images))\n",
    "n = XT.shape[0]\n",
    "y = np.zeros([2*n,2])\n",
    "y[:n,1] = 1\n",
    "y[n:,0] = 1\n",
    "\n",
    "make_trainable(discriminator,True)\n",
    "discriminator.fit(X,y, nb_epoch=1, batch_size=128)\n",
    "y_hat = discriminator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

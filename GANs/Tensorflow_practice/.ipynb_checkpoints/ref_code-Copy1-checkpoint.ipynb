{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# A bunch of utility functions\n",
    "\n",
    "def show_images(images):\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return\n",
    "\n",
    "def preprocess_img(x):\n",
    "    return 2 * x - 1.0\n",
    "\n",
    "def deprocess_img(x):\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def rel_error(x,y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def count_params():\n",
    "    \"\"\"Count the number of parameters in the current TensorFlow graph \"\"\"\n",
    "    param_count = np.sum([np.prod(x.get_shape().as_list()) for x in tf.global_variables()])\n",
    "    return param_count\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = False\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-d681c923e097>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/legion/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/legion/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/legion/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./cs231n/datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/legion/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./cs231n/datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./cs231n/datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./cs231n/datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/legion/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./cs231n/datasets/MNIST_data', one_hot=False)\n",
    "\n",
    "# show a batch\n",
    "show_images(mnist.train.next_batch(16)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"Compute the leaky ReLU activation function.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor with arbitrary shape\n",
    "    - alpha: leak parameter for leaky ReLU\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with the same shape as x\n",
    "    \"\"\"\n",
    "    # TODO: implement leaky ReLU\n",
    "    x = tf.cast(x,tf.float64)\n",
    "    h = tf.maximum(x,0)\n",
    "    return tf.where(x<=0.0,0.01*x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise(batch_size, dim):\n",
    "    \"\"\"Generate random uniform noise from -1 to 1.\n",
    "    \n",
    "    Inputs:\n",
    "    - batch_size: integer giving the batch size of noise to generate\n",
    "    - dim: integer giving the dimension of the the noise to generate\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor containing uniform noise in [-1, 1] with shape [batch_size, dim]\n",
    "    \"\"\"\n",
    "    # TODO: sample and return noise\n",
    "    return tf.random_uniform(shape=(batch_size,dim),minval=-1,maxval=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure noise is the correct shape and type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    \"\"\"Compute discriminator score for a batch of input images.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor of flattened input images, shape [batch_size, 784]\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with shape [batch_size, 1], containing the score \n",
    "    for an image being real for each input image.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"discriminator\"):\n",
    "        # TODO: implement architecture\n",
    "#        x = tf.cast(x,dtype=tf.float64)\n",
    "#        inp_shape = tf.cast(x.shape[1],tf.int64)\n",
    "#        W1 = tf.Variable(tf.random_normal(shape=(inp_shape,256),dtype=tf.float64),dtype=tf.float64)\n",
    "#        b1 = tf.Variable(tf.ones(shape=(W1.shape[1]),dtype=tf.float64))\n",
    "#        W2 = tf.Variable(tf.random_normal(shape=(256,256),dtype=tf.float64),dtype=tf.float64)\n",
    "#        b2 = tf.Variable(tf.ones(shape=(W1.shape[1]),dtype=tf.float64))\n",
    "#        W3 = tf.Variable(tf.random_normal(shape=(256,1),dtype=tf.float64),dtype=tf.float64)\n",
    "#        b3 = tf.Variable(tf.ones(shape=(W3.shape[1]),dtype=tf.float64))\n",
    "#        h1 = leaky_relu(tf.matmul(x,W1)+b1)\n",
    "#        h2 = leaky_relu(tf.matmul(h1,W2)+b2)\n",
    "#        h3 = tf.matmul(h2,W3)+b3\n",
    "#        logits = h3\n",
    "#\n",
    "\n",
    "        init = tf.contrib.layers.xavier_initializer()\n",
    "        h1 = tf.layers.dense(inputs=x,units=256,activation=leaky_relu,kernel_initializer=init,name='1-Layer',use_bias=True)\n",
    "        h2 = tf.layers.dense(inputs=h1,units=256,activation=leaky_relu,kernel_initializer=init,name='2-Layer',use_bias=True)\n",
    "        logits = tf.layers.dense(inputs=h2,units=1,kernel_initializer=init,name='3-Layer',use_bias=True)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to make sure the number of parameters in the discriminator is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \"\"\"Generate images from a random noise vector.\n",
    "    \n",
    "    Inputs:\n",
    "    - z: TensorFlow Tensor of random noise with shape [batch_size, noise_dim]\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor of generated images, with shape [batch_size, 784].\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        # TODO: implement architecture\n",
    "\n",
    "        init = tf.contrib.layers.xavier_initializer()\n",
    "        h1 = tf.layers.dense(inputs=z,units=1024,activation=tf.nn.relu,kernel_initializer=init,name='1-Layer',use_bias=True)\n",
    "        h2 = tf.layers.dense(inputs=h1,units=1024,activation=tf.nn.relu,kernel_initializer=init,name='2-Layer',use_bias=True)\n",
    "        img = tf.layers.dense(inputs=h2,units=784,activation=tf.nn.tanh,kernel_initializer=init,name='3-Layer',use_bias=True)         \n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to make sure the number of parameters in the generator is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(logits_real, logits_fake):\n",
    "    \"\"\"Compute the GAN loss.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: Tensor, shape [batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each real image\n",
    "    - logits_fake: Tensor, shape[batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each fake image\n",
    "    \n",
    "    Returns:\n",
    "    - D_loss: discriminator loss scalar\n",
    "    - G_loss: generator loss scalar\n",
    "    \"\"\"\n",
    "    # TODO: compute D_loss and G_loss\n",
    "    D_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_real), logits=logits_real))+tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(logits_fake),logits=logits_fake))\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_fake),logits=logits_fake))\n",
    "    return D_loss, G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create an AdamOptimizer for D_solver and G_solver\n",
    "def get_solvers(learning_rate=1e-3, beta1=0.5):\n",
    "    \"\"\"Create solvers for GAN training.\n",
    "    \n",
    "    Inputs:\n",
    "    - learning_rate: learning rate to use for both solvers\n",
    "    - beta1: beta1 parameter for both solvers (first moment decay)\n",
    "    \n",
    "    Returns:\n",
    "    - D_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    - G_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    \"\"\"\n",
    "    D_solver = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=beta1)\n",
    "    G_solver = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=beta1)\n",
    "    \n",
    "    return D_solver, G_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# number of images for each batch\n",
    "batch_size = 128\n",
    "# our noise dimension\n",
    "noise_dim = 96\n",
    "\n",
    "# placeholder for images from the training dataset\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# random noise fed into our generator\n",
    "z = sample_noise(batch_size, noise_dim)\n",
    "# generated images\n",
    "G_sample = generator(z)\n",
    "\n",
    "with tf.variable_scope(\"\") as scope:\n",
    "    #scale images to be -1 to 1\n",
    "    logits_real = discriminator(preprocess_img(x))\n",
    "    # Re-use discriminator weights on new inputs\n",
    "    scope.reuse_variables()\n",
    "    logits_fake = discriminator(G_sample)\n",
    "\n",
    "# Get the list of variables for the discriminator and generator\n",
    "D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator') \n",
    "\n",
    "# get our solver\n",
    "D_solver, G_solver = get_solvers()\n",
    "\n",
    "# get our loss\n",
    "D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "\n",
    "# setup training steps\n",
    "D_train_step = D_solver.minimize(D_loss, var_list=D_vars)\n",
    "G_train_step = G_solver.minimize(G_loss, var_list=G_vars)\n",
    "D_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'discriminator')\n",
    "G_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a giant helper function\n",
    "def run_a_gan(sess, G_train_step, G_loss, D_train_step, D_loss, G_extra_step, D_extra_step,\\\n",
    "              show_every=250, print_every=50, batch_size=128, num_epoch=10):\n",
    "    \"\"\"Train a GAN for a certain number of epochs.\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: A tf.Session that we want to use to run our data\n",
    "    - G_train_step: A training step for the Generator\n",
    "    - G_loss: Generator loss\n",
    "    - D_train_step: A training step for the Generator\n",
    "    - D_loss: Discriminator loss\n",
    "    - G_extra_step: A collection of tf.GraphKeys.UPDATE_OPS for generator\n",
    "    - D_extra_step: A collection of tf.GraphKeys.UPDATE_OPS for discriminator\n",
    "    Returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    # compute the number of iterations we need\n",
    "    max_iter = int(mnist.train.num_examples*num_epoch/batch_size)\n",
    "    for it in range(max_iter):\n",
    "        # every show often, show a sample result\n",
    "        if it % show_every == 0:\n",
    "            samples = sess.run(G_sample)\n",
    "            fig = show_images(samples[:16])\n",
    "            plt.show()\n",
    "            print()\n",
    "        # run a batch of data through the network\n",
    "        minibatch,minbatch_y = mnist.train.next_batch(batch_size)\n",
    "        _, D_loss_curr = sess.run([D_train_step, D_loss], feed_dict={x: minibatch})\n",
    "        _, G_loss_curr = sess.run([G_train_step, G_loss])\n",
    "\n",
    "        # print loss every so often.\n",
    "        # We want to make sure D_loss doesn't go to 0\n",
    "        if it % print_every == 0:\n",
    "            print('Iter: {}, D: {:.4}, G:{:.4}'.format(it,D_loss_curr,G_loss_curr))\n",
    "    print('Final images')\n",
    "    samples = sess.run(G_sample)\n",
    "\n",
    "    fig = show_images(samples[:16])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

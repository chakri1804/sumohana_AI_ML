{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2) (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "option = 'XOR'\n",
    "    \n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(len(Input)):\n",
    "    for j in range(10000):\n",
    "        X.append(Input[i]+np.random.normal(0,0.01,(1,2)))\n",
    "        Y.append(Output[i]+np.random.normal(0,0.01))\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape((len(Y),2))\n",
    "Y = np.array(Y)\n",
    "print(X.shape, Y.shape)\n",
    "# defining functions\n",
    "# defining functions\n",
    "input_size = 2\n",
    "hidden_nodes = 5\n",
    "output_size = 1\n",
    "samples = 40000\n",
    "lr = 1e-4\n",
    "\n",
    "def sigm(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def diff_sigm(x):\n",
    "    return (sigm(x)-(sigm(x)**2))\n",
    "\n",
    "def layer(x,W,b):\n",
    "    return np.matmul(x,W)+b\n",
    "\n",
    "W1 = np.random.normal(1e-5,1,(input_size,hidden_nodes))\n",
    "Bi1 = np.random.normal(1e-5,1,(1,hidden_nodes))\n",
    "W2 = np.random.normal(1e-5,1,(hidden_nodes,output_size))\n",
    "Bi2 = np.random.normal(1e-5,1,(1,output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 179.12233508266917\n",
      "Loss = 169.43601689494744\n",
      "Loss = 166.13617718208235\n",
      "Loss = 165.12029447537668\n",
      "Loss = 164.07448098077583\n",
      "Loss = 163.01091420262134\n",
      "Loss = 161.93244610360608\n",
      "Loss = 160.84238937231643\n",
      "Loss = 159.74410086951738\n",
      "Loss = 158.64092360348553\n",
      "Loss = 157.5361234342556\n",
      "Loss = 156.43283380117165\n",
      "Loss = 155.334010044015\n",
      "Loss = 154.24239443964572\n",
      "Loss = 153.1604921953915\n",
      "Loss = 152.09055800354835\n",
      "Loss = 151.03459236422617\n",
      "Loss = 149.9943467089555\n",
      "Loss = 148.9713363446968\n",
      "Loss = 147.96686030770144\n",
      "Loss = 146.98202728701625\n",
      "Loss = 146.0177867759443\n",
      "Loss = 145.0749644820881\n",
      "Loss = 144.15430074282202\n",
      "Loss = 143.25649025513556\n",
      "Loss = 142.38222087935077\n",
      "Loss = 141.53220870671763\n",
      "Loss = 140.70722613387946\n",
      "Loss = 139.90811954433886\n",
      "Loss = 139.13581354540293\n",
      "Loss = 138.3912996839798\n",
      "Loss = 137.67560917961706\n",
      "Loss = 136.98977130270256\n",
      "Loss = 136.3347612344491\n",
      "Loss = 135.71144309097627\n",
      "Loss = 135.12051480137617\n",
      "Loss = 134.56246139354724\n",
      "Loss = 134.037521947496\n",
      "Loss = 133.54567332039554\n",
      "Loss = 133.08663124132343\n",
      "Loss = 132.65986706886835\n",
      "Loss = 132.2646368276177\n",
      "Loss = 131.90001828992317\n",
      "Loss = 131.56495181629708\n",
      "Loss = 131.25828121734264\n",
      "Loss = 130.97879179156737\n",
      "Loss = 130.7252436826508\n",
      "Loss = 130.496399608021\n",
      "Loss = 130.29104673795322\n",
      "Loss = 130.10801301852408\n",
      "Loss = 129.94617854626878\n",
      "Loss = 129.80448275490858\n",
      "Loss = 129.68192820977626\n",
      "Loss = 129.57758176508494\n",
      "Loss = 129.4905737563601\n",
      "Loss = 129.4200957993603\n",
      "Loss = 129.36539766348832\n",
      "Loss = 129.3257835913306\n",
      "Loss = 129.30060835114787\n",
      "Loss = 129.28927323739092\n",
      "Loss = 129.29122217530252\n",
      "Loss = 129.30593803810558\n",
      "Loss = 129.33293924747744\n",
      "Loss = 129.37177669824905\n",
      "Loss = 129.42203102495085\n",
      "Loss = 129.48331020960944\n",
      "Loss = 129.55524751598074\n",
      "Loss = 129.63749972435286\n",
      "Loss = 129.7297456325489\n",
      "Loss = 129.8316847823936\n",
      "Loss = 129.9430363664184\n",
      "Loss = 130.06353826683127\n",
      "Loss = 130.19294617772783\n",
      "Loss = 130.331032762168\n",
      "Loss = 130.47758679812227\n",
      "Loss = 130.63241227140733\n",
      "Loss = 130.79532737955654\n",
      "Loss = 130.9661634179993\n",
      "Loss = 131.14476352876318\n",
      "Loss = 131.3309813018561\n",
      "Loss = 131.52467923013415\n",
      "Loss = 131.72572702930202\n",
      "Loss = 131.93399984516287\n",
      "Loss = 132.14937637972736\n",
      "Loss = 132.37173697571734\n",
      "Loss = 132.60096170485295\n",
      "Loss = 132.83692850867962\n",
      "Loss = 133.07951144136118\n",
      "Loss = 133.3285790617769\n",
      "Loss = 133.58399301758706\n",
      "Loss = 133.84560685701334\n",
      "Loss = 134.11326509542153\n",
      "Loss = 134.38680255400766\n",
      "Loss = 134.66604397763106\n",
      "Loss = 134.95080392876432\n",
      "Loss = 135.24088694521888\n",
      "Loss = 135.53608794124156\n",
      "Loss = 135.8361928250902\n",
      "Loss = 136.1409793014898\n",
      "Loss = 136.45021782447824\n",
      "Loss = 136.76367266500662\n",
      "Loss = 137.0811030580743\n",
      "Loss = 137.4022643959089\n",
      "Loss = 137.72690943645873\n",
      "Loss = 138.05478949995145\n",
      "Loss = 138.3856556302037\n",
      "Loss = 138.71925970148754\n",
      "Loss = 139.05535545585784\n",
      "Loss = 139.39369945975164\n",
      "Loss = 139.73405197226154\n",
      "Loss = 140.0761777206849\n",
      "Loss = 140.4198465817094\n",
      "Loss = 140.76483416890798\n",
      "Loss = 141.11092232908445\n",
      "Loss = 141.45789955147268\n",
      "Loss = 141.80556129487238\n",
      "Loss = 142.15371023856287\n",
      "Loss = 142.5021564633048\n",
      "Loss = 142.850717568977\n",
      "Loss = 143.19921873543623\n",
      "Loss = 143.5474927330779\n",
      "Loss = 143.89537988934813\n",
      "Loss = 144.24272801714304\n",
      "Loss = 144.5893923106561\n",
      "Loss = 144.93523521382303\n",
      "Loss = 145.28012626607963\n",
      "Loss = 145.6239419297069\n",
      "Loss = 145.9665654026038\n",
      "Loss = 146.30788641990455\n",
      "Loss = 146.64780104745378\n",
      "Loss = 146.98621146977203\n",
      "Loss = 147.32302577479228\n",
      "Loss = 147.65815773731748\n",
      "Loss = 147.99152660285628\n",
      "Loss = 148.32305687321997\n",
      "Loss = 148.65267809502464\n",
      "Loss = 148.98032465202604\n",
      "Loss = 149.30593556202464\n",
      "Loss = 149.62945427891188\n",
      "Loss = 149.95082850028527\n",
      "Loss = 150.27000998093393\n",
      "Loss = 150.58695435239278\n",
      "Loss = 150.90162094867262\n",
      "Loss = 151.2139726382003\n",
      "Loss = 151.52397566194287\n",
      "Loss = 151.8315994776392\n",
      "Loss = 152.13681661002596\n",
      "Loss = 152.43960250691262\n",
      "Loss = 152.73993540094128\n",
      "Loss = 153.03779617684748\n",
      "Loss = 153.3331682440328\n",
      "Loss = 153.62603741425028\n",
      "Loss = 153.91639178420388\n",
      "Loss = 154.2042216228658\n",
      "Loss = 154.48951926331458\n",
      "Loss = 154.77227899890738\n",
      "Loss = 155.05249698360285\n",
      "Loss = 155.3301711362592\n",
      "Loss = 155.605301048742\n",
      "Loss = 155.8778878976815\n",
      "Loss = 156.14793435973073\n",
      "Loss = 156.41544453018213\n",
      "Loss = 156.68042384480884\n",
      "Loss = 156.9428790048056\n",
      "Loss = 157.20281790470995\n",
      "Loss = 157.4602495631929\n",
      "Loss = 157.71518405661348\n",
      "Loss = 157.96763245523832\n",
      "Loss = 158.21760676203206\n",
      "Loss = 158.46511985393042\n",
      "Loss = 158.7101854255108\n",
      "Loss = 158.95281793498103\n",
      "Loss = 159.19303255240882\n",
      "Loss = 159.43084511011915\n",
      "Loss = 159.6662720551891\n",
      "Loss = 159.89933040397185\n",
      "Loss = 160.13003769858568\n",
      "Loss = 160.3584119653032\n",
      "Loss = 160.5844716747808\n",
      "Loss = 160.8082357040682\n",
      "Loss = 161.0297233003403\n",
      "Loss = 161.24895404629441\n",
      "Loss = 161.46594782715894\n",
      "Loss = 161.6807247992584\n",
      "Loss = 161.89330536008305\n",
      "Loss = 162.10371011981135\n",
      "Loss = 162.3119598742351\n",
      "Loss = 162.518075579038\n",
      "Loss = 162.7220783253791\n",
      "Loss = 162.92398931673492\n",
      "Loss = 163.12382984695333\n",
      "Loss = 163.32162127947382\n",
      "Loss = 163.51738502767185\n",
      "Loss = 163.711142536282\n",
      "Loss = 163.90291526385974\n",
      "Loss = 164.0927246662398\n",
      "Loss = 164.28059218095166\n",
      "Loss = 164.4665392125532\n",
      "Loss = 164.65058711884475\n",
      "Loss = 164.83275719792627\n",
      "Loss = 165.01307067606257\n",
      "Loss = 165.19154869632118\n",
      "Loss = 165.36821230794968\n",
      "Loss = 165.54308245645925\n",
      "Loss = 165.71617997438335\n",
      "Loss = 165.88752557268057\n",
      "Loss = 166.0571398327519\n",
      "Loss = 166.22504319904382\n",
      "Loss = 166.3912559722102\n",
      "Loss = 166.5557983028048\n",
      "Loss = 166.7186901854805\n",
      "Loss = 166.8799514536689\n",
      "Loss = 167.03960177471726\n",
      "Loss = 167.19766064545905\n",
      "Loss = 167.3541473881975\n",
      "Loss = 167.50908114707883\n",
      "Loss = 167.66248088483619\n",
      "Loss = 167.8143653798846\n",
      "Loss = 167.96475322374764\n",
      "Loss = 168.11366281879782\n",
      "Loss = 168.26111237629436\n",
      "Loss = 168.4071199147005\n",
      "Loss = 168.55170325826555\n",
      "Loss = 168.69488003585622\n",
      "Loss = 168.8366676800229\n",
      "Loss = 168.97708342628673\n",
      "Loss = 169.11614431263473\n",
      "Loss = 169.25386717921037\n",
      "Loss = 169.3902686681874\n",
      "Loss = 169.5253652238154\n",
      "Loss = 169.65917309262682\n",
      "Loss = 169.7917083237941\n",
      "Loss = 169.92298676962824\n",
      "Loss = 170.05302408620815\n",
      "Loss = 170.18183573413305\n",
      "Loss = 170.30943697938847\n",
      "Loss = 170.43584289431843\n",
      "Loss = 170.56106835869588\n",
      "Loss = 170.68512806088404\n",
      "Loss = 170.8080364990822\n",
      "Loss = 170.92980798264887\n",
      "Loss = 171.0504566334964\n",
      "Loss = 171.16999638755138\n",
      "Loss = 171.2884409962751\n",
      "Loss = 171.4058040282384\n",
      "Loss = 171.52209887074673\n",
      "Loss = 171.63733873151043\n",
      "Loss = 171.7515366403554\n",
      "Loss = 171.8647054509706\n",
      "Loss = 171.97685784268808\n",
      "Loss = 172.08800632229153\n",
      "Loss = 172.19816322585112\n",
      "Loss = 172.30734072057942\n",
      "Loss = 172.41555080670673\n",
      "Loss = 172.52280531937282\n",
      "Loss = 172.62911593053107\n",
      "Loss = 172.73449415086463\n",
      "Loss = 172.83895133170958\n",
      "Loss = 172.94249866698513\n",
      "Loss = 173.0451471951271\n",
      "Loss = 173.14690780102404\n",
      "Loss = 173.24779121795268\n",
      "Loss = 173.34780802951244\n",
      "Loss = 173.446968671556\n",
      "Loss = 173.54528343411573\n",
      "Loss = 173.6427624633237\n",
      "Loss = 173.73941576332405\n",
      "Loss = 173.83525319817696\n",
      "Loss = 173.9302844937526\n",
      "Loss = 174.02451923961445\n",
      "Loss = 174.11796689089064\n",
      "Loss = 174.2106367701326\n",
      "Loss = 174.3025380691605\n",
      "Loss = 174.39367985089393\n",
      "Loss = 174.4840710511683\n",
      "Loss = 174.573720480535\n",
      "Loss = 174.66263682604617\n",
      "Loss = 174.75082865302218\n",
      "Loss = 174.83830440680237\n",
      "Loss = 174.92507241447842\n",
      "Loss = 175.01114088660935\n",
      "Loss = 175.09651791891898\n",
      "Loss = 175.18121149397393\n",
      "Loss = 175.26522948284423\n",
      "Loss = 175.34857964674356\n",
      "Loss = 175.43126963865117\n",
      "Loss = 175.51330700491442\n",
      "Loss = 175.59469918683143\n",
      "Loss = 175.67545352221475\n",
      "Loss = 175.75557724693488\n",
      "Loss = 175.83507749644477\n",
      "Loss = 175.91396130728373\n",
      "Loss = 175.99223561856257\n",
      "Loss = 176.06990727342833\n",
      "Loss = 176.14698302050977\n",
      "Loss = 176.22346951534277\n",
      "Loss = 176.29937332177707\n",
      "Loss = 176.37470091336212\n",
      "Loss = 176.4494586747148\n",
      "Loss = 176.52365290286727\n",
      "Loss = 176.59728980859555\n",
      "Loss = 176.67037551772913\n",
      "Loss = 176.74291607244177\n",
      "Loss = 176.8149174325234\n",
      "Loss = 176.88638547663302\n",
      "Loss = 176.95732600353386\n",
      "Loss = 177.02774473330922\n",
      "Loss = 177.09764730856116\n",
      "Loss = 177.16703929559037\n",
      "Loss = 177.23592618555836\n",
      "Loss = 177.30431339563268\n",
      "Loss = 177.37220627011368\n",
      "Loss = 177.4396100815448\n",
      "Loss = 177.5065300318054\n",
      "Loss = 177.57297125318667\n",
      "Loss = 177.63893880945122\n",
      "Loss = 177.70443769687586\n",
      "Loss = 177.76947284527827\n",
      "Loss = 177.8340491190274\n",
      "Loss = 177.89817131803864\n",
      "Loss = 177.96184417875213\n",
      "Loss = 178.0250723750969\n",
      "Loss = 178.08786051943912\n",
      "Loss = 178.15021316351533\n",
      "Loss = 178.21213479935088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 178.27362986016385\n",
      "Loss = 178.33470272125453\n",
      "Loss = 178.3953577008805\n",
      "Loss = 178.45559906111808\n",
      "Loss = 178.51543100870938\n",
      "Loss = 178.57485769589655\n",
      "Loss = 178.63388322124186\n",
      "Loss = 178.69251163043484\n",
      "Loss = 178.75074691708687\n",
      "Loss = 178.80859302351215\n",
      "Loss = 178.86605384149678\n",
      "Loss = 178.92313321305485\n",
      "Loss = 178.9798349311728\n",
      "Loss = 179.03616274054136\n",
      "Loss = 179.09212033827586\n",
      "Loss = 179.14771137462492\n",
      "Loss = 179.2029394536672\n",
      "Loss = 179.2578081339976\n",
      "Loss = 179.31232092940178\n",
      "Loss = 179.36648130951983\n",
      "Loss = 179.42029270049937\n",
      "Loss = 179.47375848563794\n",
      "Loss = 179.52688200601497\n",
      "Loss = 179.57966656111338\n",
      "Loss = 179.63211540943146\n",
      "Loss = 179.6842317690845\n",
      "Loss = 179.73601881839662\n",
      "Loss = 179.7874796964834\n",
      "Loss = 179.83861750382474\n",
      "Loss = 179.88943530282847\n",
      "Loss = 179.93993611838496\n",
      "Loss = 179.99012293841275\n",
      "Loss = 180.03999871439524\n",
      "Loss = 180.08956636190868\n",
      "Loss = 180.13882876114198\n",
      "Loss = 180.18778875740747\n",
      "Loss = 180.23644916164443\n",
      "Loss = 180.2848127509131\n",
      "Loss = 180.33288226888217\n",
      "Loss = 180.38066042630757\n",
      "Loss = 180.42814990150367\n",
      "Loss = 180.47535334080695\n",
      "Loss = 180.52227335903257\n",
      "Loss = 180.568912539923\n",
      "Loss = 180.61527343659\n",
      "Loss = 180.66135857194908\n",
      "Loss = 180.70717043914752\n",
      "Loss = 180.75271150198486\n",
      "Loss = 180.79798419532753\n",
      "Loss = 180.84299092551595\n",
      "Loss = 180.887734070766\n",
      "Loss = 180.9322159815634\n",
      "Loss = 180.97643898105233\n",
      "Loss = 181.02040536541753\n",
      "Loss = 181.06411740426063\n",
      "Loss = 181.1075773409702\n",
      "Loss = 181.15078739308615\n",
      "Loss = 181.1937497526586\n",
      "Loss = 181.2364665866004\n",
      "Loss = 181.2789400370348\n",
      "Loss = 181.32117222163734\n",
      "Loss = 181.3631652339723\n",
      "Loss = 181.404921143824\n",
      "Loss = 181.4464419975228\n",
      "Loss = 181.48772981826633\n",
      "Loss = 181.52878660643498\n",
      "Loss = 181.5696143399033\n",
      "Loss = 181.61021497434584\n",
      "Loss = 181.6505904435389\n",
      "Loss = 181.690742659657\n",
      "Loss = 181.7306735135648\n",
      "Loss = 181.77038487510515\n",
      "Loss = 181.80987859338185\n",
      "Loss = 181.84915649703836\n",
      "Loss = 181.88822039453254\n",
      "Loss = 181.92707207440662\n",
      "Loss = 181.96571330555324\n",
      "Loss = 182.00414583747758\n",
      "Loss = 182.04237140055525\n",
      "Loss = 182.08039170628615\n",
      "Loss = 182.11820844754476\n",
      "Loss = 182.1558232988264\n",
      "Loss = 182.1932379164897\n",
      "Loss = 182.2304539389955\n",
      "Loss = 182.26747298714204\n",
      "Loss = 182.30429666429683\n",
      "Loss = 182.34092655662428\n",
      "Loss = 182.377364233311\n",
      "Loss = 182.4136112467867\n",
      "Loss = 182.4496691329424\n",
      "Loss = 182.4855394113449\n",
      "Loss = 182.52122358544838\n",
      "Loss = 182.55672314280278\n",
      "Loss = 182.59203955525876\n",
      "Loss = 182.62717427917016\n",
      "Loss = 182.66212875559253\n",
      "Loss = 182.6969044104799\n",
      "Loss = 182.73150265487752\n",
      "Loss = 182.7659248851125\n",
      "Loss = 182.80017248298125\n",
      "Loss = 182.83424681593416\n",
      "Loss = 182.8681492372577\n",
      "Loss = 182.90188108625378\n",
      "Loss = 182.93544368841648\n",
      "Loss = 182.968838355606\n",
      "Loss = 183.00206638622043\n",
      "Loss = 183.03512906536463\n",
      "Loss = 183.06802766501707\n",
      "Loss = 183.10076344419355\n",
      "Loss = 183.13333764910936\n",
      "Loss = 183.1657515133385\n",
      "Loss = 183.19800625797083\n",
      "Loss = 183.23010309176686\n",
      "Loss = 183.26204321131027\n",
      "Loss = 183.29382780115853\n",
      "Loss = 183.32545803399086\n",
      "Loss = 183.35693507075436\n",
      "Loss = 183.38826006080825\n",
      "Loss = 183.41943414206534\n",
      "Loss = 183.45045844113247\n",
      "Loss = 183.48133407344787\n",
      "Loss = 183.51206214341755\n",
      "Loss = 183.54264374454897\n",
      "Loss = 183.57307995958345\n",
      "Loss = 183.60337186062597\n",
      "Loss = 183.63352050927418\n",
      "Loss = 183.66352695674425\n",
      "Loss = 183.69339224399624\n",
      "Loss = 183.7231174018568\n",
      "Loss = 183.75270345114077\n",
      "Loss = 183.7821514027704\n",
      "Loss = 183.81146225789368\n",
      "Loss = 183.84063700800027\n",
      "Loss = 183.8696766350365\n",
      "Loss = 183.8985821115183\n",
      "Loss = 183.92735440064243\n",
      "Loss = 183.955994456397\n",
      "Loss = 183.98450322366958\n",
      "Loss = 184.01288163835392\n",
      "Loss = 184.04113062745583\n",
      "Loss = 184.06925110919695\n",
      "Loss = 184.09724399311744\n",
      "Loss = 184.12511018017716\n",
      "Loss = 184.15285056285526\n",
      "Loss = 184.18046602524888\n",
      "Loss = 184.2079574431702\n",
      "Loss = 184.23532568424196\n",
      "Loss = 184.26257160799224\n",
      "Loss = 184.28969606594745\n",
      "Loss = 184.31669990172432\n",
      "Loss = 184.3435839511206\n",
      "Loss = 184.37034904220445\n",
      "Loss = 184.39699599540282\n",
      "Loss = 184.42352562358838\n",
      "Loss = 184.44993873216558\n",
      "Loss = 184.47623611915515\n",
      "Loss = 184.5024185752781\n",
      "Loss = 184.52848688403793\n",
      "Loss = 184.55444182180202\n",
      "Loss = 184.58028415788235\n",
      "Loss = 184.60601465461414\n",
      "Loss = 184.6316340674347\n",
      "Loss = 184.65714314496012\n",
      "Loss = 184.6825426290618\n",
      "Loss = 184.7078332549413\n",
      "Loss = 184.73301575120473\n",
      "Loss = 184.75809083993593\n",
      "Loss = 184.78305923676862\n",
      "Loss = 184.80792165095764\n",
      "Loss = 184.8326787854497\n",
      "Loss = 184.85733133695237\n",
      "Loss = 184.88187999600277\n",
      "Loss = 184.90632544703556\n",
      "Loss = 184.93066836844912\n",
      "Loss = 184.95490943267217\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs = 500\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    w1 = np.zeros(W1.shape)\n",
    "    b1 = np.zeros(Bi1.shape)\n",
    "    w2 = np.zeros(W2.shape)\n",
    "    b2 = np.zeros(Bi2.shape)\n",
    "    S  = np.zeros(W1.shape)\n",
    "    out1 = layer(X,W1,Bi1)\n",
    "    #Forward pass\n",
    "    z = sigm(out1)\n",
    "    out2 = layer(z,W2,Bi2)\n",
    "    y = sigm(out2)\n",
    "    #BACKPROPAGATION\n",
    "    del1 = 2*(y-Y)*diff_sigm(out2)\n",
    "    b2 = np.sum(del1, axis = 0).reshape(np.shape(Bi2))\n",
    "    w2 = np.matmul(z.T,del1)\n",
    "#     print(b2.shape,w2.shape)\n",
    "    s1 = -np.multiply(diff_sigm(out1),np.sum(del1, axis=1).reshape(samples,1))\n",
    "    b1 = np.sum(s1,axis=0).reshape(np.shape(Bi1))\n",
    "    w1 = np.matmul(X.T,s1)\n",
    "    loss = np.sum(np.linalg.norm(y-X))\n",
    "    print(\"Loss =\",loss)\n",
    "    W1 -= lr*w1\n",
    "    W2 -= lr*w2\n",
    "    Bi1 -= lr*b1\n",
    "    Bi2 -= lr*b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test sample one by one: 1,1\n",
      "(2,)\n",
      "XOR : 0\n",
      "Enter test sample one by one: 0,00\n",
      "(2,)\n",
      "XOR : 0\n",
      "Enter test sample one by one: 1,0\n",
      "(2,)\n",
      "XOR : 1\n",
      "Enter test sample one by one: 0,1\n",
      "(2,)\n",
      "XOR : 1\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    a=input(\"Enter test sample one by one: \").split(',')\n",
    "    for i in range(0,2):\n",
    "        a[i]=float(a[i])\n",
    "    a=np.array(a)\n",
    "    print(a.shape)\n",
    "    out_1 = layer(a,W1,Bi1)\n",
    "    z = sigm(out_1)\n",
    "    out_2 = layer(z,W2,Bi2)\n",
    "    y_pred= sigm(out_2)\n",
    "    if(y_pred >= 0.5):\n",
    "        y_pred = 1\n",
    "    else :\n",
    "        y_pred = 0\n",
    "    print(option,':',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
